"""Interface terminal pour l'interaction avec l'IA"""

import sys
import os
from typing import Optional
from src.modules import OllamaClient, CommandParser, CommandExecutor, AutonomousAgent
from src.utils import (
    CommandLogger,
    InputValidator
)
from src.utils.tag_parser import TagParser
from src.security import SecurityValidator
from src.core import ShellEngine, ShellMode, HistoryManager, BuiltinCommands
from src.utils.command_helpers import CommandResultHandler, handle_command_errors
from src.terminal.display_manager import DisplayManager
from src.terminal.tag_display import TagDisplay
from src.terminal.ai_stream_processor import AIStreamProcessor
from src.terminal.rich_console import get_console
from src.terminal import rich_components
from simple_term_menu import TerminalMenu
from config import prompts, project_templates, constants
from config.constants import MAX_AUTO_ITERATIONS

class TerminalInterface:
    """Interface en ligne de commande pour le Terminal IA"""

    def __init__(self, settings, logger, cache_manager=None, user_config=None):
        """
        Initialise l'interface terminal

        Args:
            settings: Configuration de l'application
            logger: Logger principal
            cache_manager: Gestionnaire de cache optionnel (Phase 1)
            user_config: Gestionnaire de configuration utilisateur
        """
        self.settings = settings
        self.logger = logger
        self.cache_manager = cache_manager
        self.user_config = user_config
        self.running = False
        self.console = get_console()  # Console Rich unifi√©e

        # Initialiser le moteur du shell hybride
        default_mode = ShellMode.MANUAL  # Mode par d√©faut: MANUAL
        self.shell_engine = ShellEngine(default_mode)
        self.logger.info(f"Shell initialis√© en mode {default_mode.value}")

        # Initialiser le gestionnaire d'historique
        self.history_manager = HistoryManager()
        self.logger.info(f"Historique charg√©: {len(self.history_manager)} commandes")

        # Initialiser les commandes builtins
        self.builtins = BuiltinCommands(self)
        self.logger.info(f"Commandes builtins charg√©es: {len(self.builtins.get_builtin_names())}")

        # Initialiser les utilitaires d'affichage (Refactoring)
        self.input_validator = InputValidator()
        self.tag_display = TagDisplay(self.console)  # Affichage des balises IA
        self.tag_parser = TagParser()  # Parser de balises

        # Initialiser le gestionnaire de r√©sultats unifi√© (Refactoring Phase 1.3)
        self.result_handler = CommandResultHandler(self)

        # Initialiser le processeur de streaming IA (Refactoring: √©limination duplication)
        self.stream_processor = None  # Initialis√© apr√®s parser

        # Initialisation des composants
        self.logger.info("Initialisation des composants...")

        try:
            # Client Ollama (avec cache si disponible)
            self.ollama = OllamaClient(
                host=settings.ollama_host,
                model=settings.ollama_model,
                timeout=settings.ollama_timeout,
                logger=logger,
                cache_manager=cache_manager
            )

            # Pr√©chauffer le mod√®le pour √©viter le timeout sur la premi√®re requ√™te
            if settings.auto_warmup:
                self._warmup_ollama_model()

            # Parser de commandes
            self.parser = CommandParser(self.ollama, logger)

            # Processeur de streaming IA (maintenant que parser est initialis√©)
            self.stream_processor = AIStreamProcessor(
                self.console,
                self.tag_parser,
                self.tag_display,
                self.parser
            )

            # Ex√©cuteur de commandes (avec shell PTY persistant)
            self.executor = CommandExecutor(settings, logger, use_pty=True)
            self.logger.info("CommandExecutor initialis√© avec shell PTY persistant")

            # Validateur de s√©curit√©
            self.security = SecurityValidator(logger)

            # Logger de commandes
            self.command_logger = CommandLogger(settings.logs_dir)

            # Agent autonome (si activ√©)
            self.agent = None
            if settings.agent_enabled:
                self.agent = AutonomousAgent(
                    self.ollama,
                    self.executor,
                    settings,
                    logger
                )

            # Initialiser le DisplayManager avec tous les composants
            components = {
                'settings': self.settings,
                'logger': self.logger,
                'shell_engine': self.shell_engine,
                'security': self.security,
                'history_manager': self.history_manager,
                'ollama': self.ollama,
                'executor': self.executor,
                'cache_manager': self.cache_manager,
                'agent': self.agent,
                'input_validator': self.input_validator,
                'user_config': self.user_config
            }
            self.display_manager = DisplayManager(components)

            # Configurer les callbacks de l'agent (si activ√©)
            if self.agent:
                self.agent.on_step_start = self.display_manager.on_agent_step_start
                self.agent.on_step_complete = self.display_manager.on_agent_step_complete
                self.agent.on_error = self.display_manager.on_agent_error

            self.logger.info("Composants initialis√©s avec succ√®s")

        except Exception as e:
            self.logger.error(f"Erreur lors de l'initialisation: {e}", exc_info=True)
            raise

    def _warmup_ollama_model(self):
        """
        Pr√©chauffe le mod√®le Ollama pour √©viter le timeout sur la premi√®re requ√™te.

        Le premier appel √† Ollama charge le mod√®le en m√©moire, ce qui peut prendre
        90+ secondes. Cette m√©thode effectue une requ√™te de warmup au d√©marrage
        pour que les vraies requ√™tes soient instantan√©es.
        """
        try:
            # Afficher un indicateur de chargement avec Rich
            with self.console.create_status("Chargement du mod√®le Ollama...") as status:
                # Requ√™te minimale pour forcer le chargement du mod√®le
                warmup_prompt = "test"
                warmup_system = "R√©ponds seulement 'ok'"
                self.ollama.generate(warmup_prompt, system_prompt=warmup_system)

            self.logger.info("Mod√®le Ollama pr√©chauff√© avec succ√®s")

        except Exception as e:
            # Ne pas bloquer le d√©marrage si le warmup √©choue
            self.logger.warning(f"√âchec du pr√©chauffage Ollama: {e}")
            self.console.warning(f"Le pr√©chauffage du mod√®le a √©chou√©: {e}")

    def run(self):
        """Lance la boucle principale du terminal"""
        self.running = True

        # Afficher le banner avec Rich
        mode_name = self.shell_engine.mode_name.upper()
        self.console.print_banner(
            model=self.settings.ollama_model,
            host=self.settings.ollama_host,
            mode=mode_name,
            mode_description=self.shell_engine.get_mode_description()
        )

        # V√©rifier la connexion √† Ollama
        if not self.ollama.check_connection():
            warning_msg = f"Impossible de se connecter √† Ollama!\n"
            warning_msg += f"V√©rifiez que Ollama est lanc√© sur {self.settings.ollama_host}\n\n"
            warning_msg += "[dim]Vous pouvez continuer mais les commandes ne seront pas pars√©es.[/dim]"

            self.console.print(rich_components.create_warning_panel(warning_msg))

        # Boucle principale
        try:
            while self.running:
                self._process_input()
        except KeyboardInterrupt:
            self.console.print("\n")
            self.console.info("Interruption d√©tect√©e...")
            self._quit()
        except Exception as e:
            self.logger.error(f"Erreur dans la boucle principale: {e}", exc_info=True)
            self.console.print()
            self.console.error(f"Erreur fatale: {e}")
            self._quit()

    def _process_input(self):
        """Traite une entr√©e utilisateur"""
        try:
            # Afficher le prompt avec Rich
            current_dir = self.executor.get_current_directory()
            mode_name = self.shell_engine.mode_name.upper()
            prompt_text = self.console.get_prompt_text(current_dir, mode_name)

            # Lire l'entr√©e utilisateur
            user_input = self.console.input(prompt_text).strip()

            if not user_input:
                return

            # Traiter la commande
            if user_input.startswith('/'):
                self._handle_special_command(user_input)
            else:
                self._handle_user_request(user_input)

        except EOFError:
            self.console.print("\n")
            self._quit()
        except KeyboardInterrupt:
            self.console.print("\n")
            raise

    def _handle_special_command(self, command: str):
        """
        G√®re les commandes sp√©ciales

        Args:
            command: Commande sp√©ciale (commence par /)
        """
        cmd_lower = command.lower()

        if cmd_lower == '/quit' or cmd_lower == '/exit':
            self._quit()

        elif cmd_lower == '/help':
            self.console.print_help(prompts.HELP_TEXT)

        elif cmd_lower == '/manual':
            # Basculer en mode MANUAL
            if self.shell_engine.switch_to_manual():
                self.logger.info("Changement de mode: ‚Üí MANUAL")
                self.console.print()
                self.console.success("Mode MANUAL activ√©")
                self.console.print(f"[dim]{self.shell_engine.get_mode_description()}[/dim]")
            else:
                self.console.print()
                self.console.info("D√©j√† en mode MANUAL")

        elif cmd_lower == '/auto':
            # Basculer en mode AUTO
            if self.shell_engine.switch_to_auto():
                self.logger.info("Changement de mode: ‚Üí AUTO (it√©ratif)")
                self.console.print()
                self.console.success("Mode AUTO activ√©")
                self.console.print(f"[dim]{self.shell_engine.get_mode_description()}[/dim]")
            else:
                self.console.print()
                self.console.info("D√©j√† en mode AUTO")

        elif cmd_lower == '/fast':
            # Basculer en mode FAST
            if self.shell_engine.switch_to_fast():
                self.logger.info("Changement de mode: ‚Üí FAST (one-shot)")
                self.console.print()
                self.console.success("Mode FAST activ√©")
                self.console.print(f"[dim]{self.shell_engine.get_mode_description()}[/dim]")
            else:
                self.console.print()
                self.console.info("D√©j√† en mode FAST")

        elif cmd_lower == '/status':
            # Afficher le statut du shell
            self.display_manager.show_shell_status()

        elif cmd_lower == '/clear':
            self.logger.info("Effacement de l'historique demand√©")
            self.parser.clear_history()
            self.ollama.clear_history()
            self.console.print()
            self.console.success("Historique effac√©")

        elif cmd_lower == '/history':
            self.display_manager.show_history()

        elif cmd_lower == '/models' or cmd_lower == '/change':
            self.display_manager.list_models()

        elif cmd_lower == '/info':
            self.display_manager.show_system_info()

        elif cmd_lower == '/templates':
            self.display_manager.list_templates()

        elif cmd_lower.startswith('/agent'):
            # Mode agent autonome
            if self.agent:
                # Basculer en mode AGENT
                self.shell_engine.switch_to_agent()

                # Extraire la demande apr√®s /agent
                request = command[6:].strip()
                if request:
                    self._handle_autonomous_mode(request)
                else:
                    self.console.print()
                    self.console.info("Usage: /agent <votre demande>")
                    self.console.print("[dim]Exemple: /agent cr√©e-moi une API FastAPI[/dim]")
            else:
                self.console.print()
                self.console.error("Mode agent autonome d√©sactiv√©")

        elif cmd_lower == '/pause':
            if self.agent and self.agent.is_running:
                self.agent.pause()
                self.console.print()
                self.console.print(prompts.AGENT_PAUSED)
            else:
                self.console.print()
                self.console.error("Aucun agent en cours d'ex√©cution")

        elif cmd_lower == '/resume':
            if self.agent and self.agent.is_paused:
                self.agent.resume()
                self.console.print()
                self.console.success("Agent repris")
            else:
                self.console.print()
                self.console.error("Aucun agent en pause")

        elif cmd_lower == '/stop':
            if self.agent and self.agent.is_running:
                self.agent.stop()
                self.console.print()
                self.console.print(prompts.AGENT_STOPPED)
            else:
                self.console.print()
                self.console.error("Aucun agent en cours d'ex√©cution")

        elif cmd_lower.startswith('/cache'):
            # Commandes de gestion du cache (Phase 1)
            parts = command.split()
            if len(parts) == 1:
                # /cache seul = afficher stats
                self.display_manager.show_cache_stats()
            elif parts[1].lower() == 'stats':
                self.display_manager.show_cache_stats()
            elif parts[1].lower() == 'clear':
                self.display_manager.clear_cache()
            else:
                self.console.print()
                self.console.error("Commande cache inconnue")
                self.console.print("[dim]Usage: /cache [stats|clear][/dim]")

        elif cmd_lower == '/hardware':
            self.display_manager.show_hardware_info()

        elif cmd_lower.startswith('/rollback'):
            # Commandes de rollback (Phase 2)
            if not self.agent:
                self.console.print()
                self.console.error("Le mode agent n'est pas activ√©")
                return

            parts = command.split()
            if len(parts) == 1:
                # /rollback seul = afficher snapshots disponibles
                self.display_manager.show_snapshots()
            elif parts[1].lower() == 'list':
                self.display_manager.show_snapshots()
            elif parts[1].lower() == 'restore':
                # /rollback restore [snapshot_id]
                snapshot_id = parts[2] if len(parts) > 2 else None
                self.display_manager.restore_snapshot(snapshot_id)
            elif parts[1].lower() == 'stats':
                self.display_manager.show_rollback_stats()
            else:
                self.console.print()
                self.console.error("Commande rollback inconnue")
                self.console.print("[dim]Usage: /rollback [list|restore|stats][/dim]")

        elif cmd_lower == '/security':
            # Commande de rapport de s√©curit√© (Phase 2)
            self.display_manager.show_security_report()

        elif cmd_lower.startswith('/corrections'):
            # Commandes d'auto-correction (Phase 3)
            if not self.agent:
                self.console.print()
                self.console.error("Le mode agent n'est pas activ√©")
                return

            parts = command.split()
            if len(parts) == 1 or parts[1].lower() == 'stats':
                self.display_manager.show_correction_stats()
            elif parts[1].lower() == 'last':
                self.display_manager.show_last_error()
            else:
                self.console.print()
                self.console.error("Commande corrections inconnue")
                self.console.print("[dim]Usage: /corrections [stats|last][/dim]")

        else:
            self.console.print()
            self.console.error(f"Commande inconnue: {command}")
            self.console.print("[dim]Tapez /help pour voir les commandes disponibles[/dim]")

    def _handle_user_request(self, user_input: str):
        """
        G√®re une demande utilisateur normale

        Args:
            user_input: Demande de l'utilisateur
        """
        # Incr√©menter le compteur de commandes
        self.shell_engine.increment_command_count()

        try:
            # MODE MANUAL : Ex√©cution directe sans IA
            if self.shell_engine.is_manual_mode():
                self._handle_manual_mode(user_input)
                return

            # MODE AUTO : Parsing IA it√©ratif avec boucle
            elif self.shell_engine.is_auto_mode():
                self.console.print()
                self._handle_auto_mode(user_input)
                return

            # MODE FAST : Parsing IA one-shot (une commande et c'est fini)
            elif self.shell_engine.is_fast_mode():
                self.console.print()
                self._handle_fast_mode(user_input)
                return

            # MODE AGENT : Toujours proposer le mode autonome
            elif self.shell_engine.is_agent_mode():
                self.console.print()
                self.console.info("Mode AGENT : Analyse en cours...")
                self._handle_autonomous_mode(user_input)
                return

        except Exception as e:
            self.logger.error(f"Erreur lors du traitement: {e}", exc_info=True)
            self.console.print()
            self.console.error(f"Erreur: {e}")

    def _handle_manual_mode(self, user_input: str):
        """
        G√®re les commandes en mode MANUAL (ex√©cution directe)

        Args:
            user_input: Commande shell √† ex√©cuter
        """
        try:
            # V√©rifier si c'est une commande builtin
            if self.builtins.is_builtin(user_input):
                result = self.builtins.execute(user_input)
                if result is not None:
                    # Commande builtin ex√©cut√©e - utiliser le handler unifi√©
                    self.result_handler.handle_result(
                        result=result,
                        command=user_input,
                        user_input=user_input,
                        mode="manual"
                    )
                    return

            # Ex√©cuter via shell PTY persistant (VRAI TERMINAL)
            # Avantages vs subprocess :
            # - Variables d'environnement persistent (export fonctionne)
            # - cd natif fonctionne
            # - Aliases et functions shell fonctionnent
            # - Session unique (comme bash/zsh)

            # Callback pour afficher la sortie en temps r√©el
            def stream_output(line):
                """Affiche chaque ligne de sortie en temps r√©el"""
                self.console.print(f"[output]{line}[/output]")

            # Ex√©cution avec shell PTY
            self.console.print()  # Ligne vide avant la sortie
            result = self.executor.execute_pty(
                user_input,
                output_callback=stream_output
            )

            # Traiter le r√©sultat via le handler unifi√© (display + history + logging)
            # skip_output=True car d√©j√† affich√© en temps r√©el
            self.result_handler.handle_result(
                result=result,
                command=user_input,
                user_input=user_input,
                mode="manual",
                skip_output=True
            )

        except Exception as e:
            self.logger.error(f"Erreur mode manuel: {e}", exc_info=True)
            self.console.error(f"Erreur: {e}")

    def _stream_ai_response_with_tags(self, user_input: str) -> dict:
        """
        Stream la r√©ponse IA avec affichage des balises en temps r√©el

        Args:
            user_input: Demande utilisateur

        Returns:
            Dict avec command, explanation, risk_level, parsed_sections
        """
        # Obtenir le g√©n√©rateur de streaming
        stream_gen = self.parser.parse_user_request_stream(user_input)

        # D√©l√©guer au processeur de streaming (Refactoring: √©limination duplication)
        return self.stream_processor.process_stream(
            stream_gen,
            user_input,
            context_label="STREAMING"
        )

    def _stream_ai_response_with_history(self, user_input: str, context_history: list) -> dict:
        """
        Stream la r√©ponse IA avec historique (pour mode it√©ratif)

        Args:
            user_input: Demande utilisateur initiale
            context_history: Historique des √©tapes pr√©c√©dentes

        Returns:
            Dict avec command, explanation, risk_level, parsed_sections
        """
        self.logger.info(f"[STREAMING WITH HISTORY] Step avec {len(context_history)} √©tapes pr√©c√©dentes")

        # Obtenir le g√©n√©rateur de streaming avec historique
        stream_gen = self.parser.parse_with_history(user_input, context_history)

        # D√©l√©guer au processeur de streaming (Refactoring: √©limination duplication)
        return self.stream_processor.process_stream(
            stream_gen,
            user_input,
            context_label="STREAMING WITH HISTORY"
        )

    def _is_task_completed(self, explanation: str) -> bool:
        """
        D√©tecte si la t√¢che est compl√©t√©e bas√© sur l'explication de l'IA

        Args:
            explanation: L'explication fournie par l'IA

        Returns:
            True si la t√¢che est termin√©e
        """
        if not explanation:
            return False

        # Chercher les marqueurs de compl√©tion
        completion_markers = [
            "‚úì T√¢che termin√©e",
            "‚úì t√¢che termin√©e",
            "t√¢che termin√©e",
            "t√¢che compl√©t√©e",
            "objectif atteint",
            "‚úó Impossible de continuer",
            "impossible de continuer",
            "pas de solution",
            "aucune commande appropri√©e"
        ]

        explanation_lower = explanation.lower()
        for marker in completion_markers:
            if marker.lower() in explanation_lower:
                return True

        return False

    def _prompt_next_action_with_arrows(self) -> str:
        """
        Demande √† l'utilisateur ce qu'il veut faire (avec s√©lection par fl√®ches)

        Returns:
            "continue", "stop", ou "improve"
        """
        options = [
            "‚Üí Continuer (prochaine √©tape)",
            "‚èπ  Arr√™ter (termin√©)",
            "‚úè  Am√©liorer (pr√©ciser)"
        ]

        try:
            self.console.print()
            terminal_menu = TerminalMenu(
                options,
                title="Que souhaitez-vous faire ? (‚Üë‚Üì pour naviguer, Entr√©e pour valider)",
                cursor_index=0  # Par d√©faut sur "Continuer"
            )

            menu_index = terminal_menu.show()

            if menu_index is None:
                # Utilisateur a annul√© (Ctrl+C)
                self.console.print()
                return "stop"
            elif menu_index == 0:
                return "continue"
            elif menu_index == 1:
                return "stop"
            elif menu_index == 2:
                return "improve"
            else:
                # Fallback par d√©faut
                return "continue"

        except KeyboardInterrupt:
            self.console.print()
            return "stop"
        except Exception as e:
            self.logger.error(f"Erreur lors de la s√©lection: {e}")
            return "stop"

    def _handle_fast_mode(self, user_input: str):
        """
        G√®re les commandes en mode FAST (IA one-shot, pas de boucle it√©rative)

        Args:
            user_input: Demande en langage naturel
        """
        self.logger.info(f"Entr√©e en mode FAST one-shot - Demande: {user_input[:100]}...")
        try:
            # Parser la demande avec streaming (affichage en temps r√©el avec balises)
            # Utilise SYSTEM_PROMPT_FAST via un prompt syst√®me modifi√©
            self.console.info("‚ö° Mode FAST - G√©n√©ration d'une commande optimale...")

            # Temporairement changer le prompt syst√®me pour mode FAST
            from config.prompts import SYSTEM_PROMPT_FAST
            original_prompt = self.parser._get_parsing_system_prompt

            # Override temporaire de la m√©thode pour utiliser SYSTEM_PROMPT_FAST
            self.parser._get_parsing_system_prompt = lambda: SYSTEM_PROMPT_FAST

            try:
                parsed = self._stream_ai_response_with_tags(user_input)
            finally:
                # Restaurer le prompt original
                self.parser._get_parsing_system_prompt = original_prompt

            command = parsed.get('command')
            risk_level = parsed.get('risk_level', 'unknown')
            explanation = parsed.get('explanation', '')

            if not command:
                # Pas de commande g√©n√©r√©e
                return

            # Valider la s√©curit√©
            is_valid, security_level, security_reason = self.security.validate_command(command)

            if not is_valid:
                self.console.print()
                self.console.error("Commande bloqu√©e")
                self.console.print(f"   Raison: {security_reason}")
                self.logger.warning(f"Commande bloqu√©e: {command} - {security_reason}")
                return

            # Demander confirmation si n√©cessaire
            if security_level == 'high' or risk_level == 'high':
                if not self._confirm_command(command, security_level, security_reason):
                    self.console.error("Commande annul√©e")
                    return

            # Ex√©cuter la commande avec streaming
            self.console.info("Ex√©cution...")
            self.console.print()  # Ligne vide avant la sortie

            # Callback pour afficher la sortie en temps r√©el
            def stream_output(line):
                """Affiche chaque ligne de sortie en temps r√©el"""
                self.console.print(f"[output]{line}[/output]")

            result = self.executor.execute_streaming(
                command,
                output_callback=stream_output,
                strict_mode=False
            )

            # Traiter le r√©sultat
            self.result_handler.handle_result(
                result,
                command,
                user_input,
                "fast",
                skip_output=True
            )

            # Enregistrer dans l'historique de s√©curit√©
            self.security.record_command_execution(
                command=command,
                success=result['success'],
                risk_level=security_level
            )

            # Ajouter √† l'historique du parser
            self.parser.add_to_history(user_input, command, result.get('output', ''))

            self.logger.info(f"Fin du mode FAST one-shot - Commande: {command}")

        except Exception as e:
            self.logger.error(f"Erreur mode fast: {e}", exc_info=True)
            self.console.error(f"Erreur: {e}")

    def _handle_auto_mode(self, user_input: str):
        """
        G√®re les commandes en mode AUTO (avec IA - MODE IT√âRATIF)
        Boucle it√©rative : commande ‚Üí r√©sultat ‚Üí IA d√©cide prochaine √©tape

        Args:
            user_input: Demande en langage naturel
        """
        self.logger.info(f"Entr√©e en mode AUTO it√©ratif - Demande: {user_input[:100]}...")
        try:
            # NOTE: D√©tection automatique de complexit√© D√âSACTIV√âE
            # L'utilisateur peut basculer manuellement en mode AGENT avec /agent
            # Cela √©vite les faux positifs et donne plus de contr√¥le √† l'utilisateur

            # if self.agent and self.settings.agent_enabled:
            #     with self.console.create_status("Analyse de la complexit√©...") as status:
            #         analysis = self.agent.planner.analyze_request(user_input)
            #
            #     if analysis.get('is_complex'):
            #         self.console.print()
            #         self.console.info(f"Projet complexe d√©tect√©: {analysis.get('project_type')}")
            #         self.console.info("Activation du mode agent autonome disponible")
            #
            #         response = input("\nUtiliser le mode agent autonome? (oui/non): ").strip().lower()
            #         if response in ['oui', 'o', 'yes', 'y']:
            #             self.shell_engine.switch_to_agent()
            #             self._handle_autonomous_mode(user_input)
            #             return
            #         else:
            #             self.console.warning("Mode agent annul√©, traitement en mode it√©ratif")

            # BOUCLE IT√âRATIVE
            context_history = []  # Historique des commandes et r√©sultats
            step_number = 0
            self.logger.info(f"D√©marrage de la boucle it√©rative (max {MAX_AUTO_ITERATIONS} √©tapes)")

            while step_number < MAX_AUTO_ITERATIONS:
                step_number += 1
                self.logger.debug(f"It√©ration {step_number}/{MAX_AUTO_ITERATIONS}")
                self.console.print()
                self.console.info(f"üîÑ √âtape {step_number}/{MAX_AUTO_ITERATIONS}")

                # Utiliser parse_with_history pour le contexte conversationnel
                if context_history:
                    # Avec historique (√©tapes > 1)
                    self.logger.debug(f"G√©n√©ration avec historique ({len(context_history)} √©tapes pr√©c√©dentes)")
                    parsed = self._stream_ai_response_with_history(user_input, context_history)
                else:
                    # Premi√®re √©tape, pas d'historique
                    self.logger.debug("Premi√®re g√©n√©ration (sans historique)")
                    self.console.info("Analyse de votre demande...")
                    parsed = self._stream_ai_response_with_tags(user_input)

                command = parsed.get('command')
                risk_level = parsed.get('risk_level', 'unknown')
                explanation = parsed.get('explanation', '')

                self.logger.info(f"Commande g√©n√©r√©e: {command}")
                self.logger.debug(f"Risk level: {risk_level}, Explication: {explanation[:100]}...")

                if not command:
                    # Pas de commande g√©n√©r√©e
                    self.logger.warning("Aucune commande g√©n√©r√©e par l'IA")
                    self.console.warning("Aucune commande g√©n√©r√©e")
                    break

                # Valider la s√©curit√©
                is_valid, security_level, security_reason = self.security.validate_command(command)

                if not is_valid:
                    self.console.print()
                    self.console.error("Commande bloqu√©e")
                    self.console.print(f"   Raison: {security_reason}")
                    self.logger.warning(f"Commande bloqu√©e: {command} - {security_reason}")
                    break

                # Demander confirmation si n√©cessaire
                if security_level == 'high' or risk_level == 'high':
                    if not self._confirm_command(command, security_level, security_reason):
                        self.console.error("Commande annul√©e")
                        break

                # Ex√©cuter la commande
                self.console.info("Ex√©cution...")
                self.console.print()

                def stream_output(line):
                    self.console.print(f"[output]{line}[/output]")

                result = self.executor.execute_streaming(
                    command,
                    output_callback=stream_output,
                    strict_mode=False
                )

                # Enregistrer dans l'historique
                self.result_handler.handle_result(
                    result,
                    command,
                    user_input,
                    "auto",
                    skip_output=True
                )

                self.security.record_command_execution(
                    command=command,
                    success=result['success'],
                    risk_level=security_level
                )

                self.parser.add_to_history(user_input, command, result.get('output', ''))

                # Ajouter au contexte it√©ratif
                context_history.append({
                    'command': command,
                    'output': result.get('output', ''),
                    'success': result['success']
                })
                self.logger.debug(f"Contexte mis √† jour: {len(context_history)} √©tapes au total")

                # D√©tecter si la t√¢che est compl√©t√©e
                is_completed = self._is_task_completed(explanation)

                if is_completed:
                    self.logger.info("T√¢che d√©tect√©e comme compl√©t√©e par l'IA")
                    self.console.print()
                    self.console.success("‚úì T√¢che compl√©t√©e!")
                    break

                # Demander √† l'utilisateur s'il veut continuer
                user_choice = self._prompt_next_action_with_arrows()
                self.logger.info(f"Choix utilisateur: {user_choice}")

                if user_choice == "stop":
                    self.logger.info("Arr√™t de la boucle it√©rative demand√© par l'utilisateur")
                    self.console.info("Arr√™t demand√© par l'utilisateur")
                    break
                elif user_choice == "improve":
                    # Demander des pr√©cisions suppl√©mentaires
                    improvement = input("\nüí¨ Que voulez-vous pr√©ciser/am√©liorer ? ").strip()
                    if improvement:
                        self.logger.info(f"Pr√©cision utilisateur ajout√©e: {improvement[:100]}...")
                        user_input = f"{user_input}\n\nPr√©cision: {improvement}"
                        self.console.success("Pr√©cision prise en compte")
                    continue
                elif user_choice == "continue":
                    # Continuer l'it√©ration
                    self.logger.debug("Utilisateur a choisi de continuer")
                    continue

            # Fin de la boucle
            if step_number >= MAX_AUTO_ITERATIONS:
                self.logger.warning(f"Limite de {MAX_AUTO_ITERATIONS} it√©rations atteinte")
                self.console.warning(f"‚ö†Ô∏è  Limite de {MAX_AUTO_ITERATIONS} it√©rations atteinte")

            self.logger.info(f"Fin du mode AUTO it√©ratif - {step_number} √©tapes ex√©cut√©es")

        except KeyboardInterrupt:
            self.logger.info("Interruption par l'utilisateur (Ctrl+C) en mode AUTO")
            self.console.print()
            self.console.warning("Interruption par l'utilisateur (Ctrl+C)")
        except Exception as e:
            self.logger.error(f"Erreur mode auto: {e}", exc_info=True)
            self.console.error(f"Erreur: {e}")

    def _confirm_command(self, command: str, risk_level: str, reason: str) -> bool:
        """
        Demande confirmation pour une commande √† risque

        Args:
            command: La commande √† confirmer
            risk_level: Niveau de risque
            reason: Raison du risque

        Returns:
            True si l'utilisateur confirme
        """
        message = self.security.get_confirmation_message(command, risk_level, reason)
        print(message)

        while True:
            response = input("\nVotre r√©ponse (oui/non): ").strip().lower()
            if response in ['oui', 'o', 'yes', 'y']:
                return True
            elif response in ['non', 'n', 'no']:
                return False
            else:
                print("R√©ponse invalide. Tapez 'oui' ou 'non'")

    def _handle_autonomous_mode(self, user_request: str):
        """
        G√®re une demande en mode agent autonome

        Args:
            user_request: Demande utilisateur
        """
        if not self.agent:
            self.console.error("Mode agent non disponible")
            return

        try:
            print(prompts.AGENT_MODE_BANNER)
            print(prompts.AGENT_ANALYZING)

            # Analyser et g√©n√©rer le plan
            result = self.agent.execute_autonomous_task(user_request)

            if not result.get('success'):
                if result.get('reason') == 'not_complex':
                    self.console.info("Cette demande ne n√©cessite pas le mode autonome.")
                    self.console.print("   Elle sera trait√©e en mode commande simple.")
                    # Retourner au mode normal
                    return
                else:
                    self.console.error(result.get('message', 'Erreur inconnue'))
                    return

            # Afficher le plan
            plan = result.get('plan')
            if not plan:
                self.console.error("Impossible de g√©n√©rer un plan")
                return

            print("\n" + self.agent.planner.display_plan(plan))

            # Demander confirmation
            from rich.rule import Rule
            self.console.print(Rule(style="dim"))
            response = input("\nVoulez-vous lancer l'ex√©cution? (oui/non/modifier): ").strip().lower()

            if response in ['oui', 'o', 'yes', 'y']:
                # Lancer l'ex√©cution
                print(prompts.AGENT_EXECUTING)

                exec_result = self.agent.execute_plan(plan)

                if exec_result.get('success'):
                    print(prompts.AGENT_COMPLETED)
                    print(f"\n‚ú® Projet cr√©√© dans: {exec_result.get('project_path')}")

                    # Afficher r√©sum√©
                    results = exec_result.get('results', [])
                    print(f"\nüìä R√©sum√©: {len(results)} √©tapes ex√©cut√©es")

                elif exec_result.get('stopped'):
                    print(prompts.AGENT_STOPPED)
                else:
                    print(prompts.AGENT_ERROR)
                    print(f"Erreur: {exec_result.get('error', 'Erreur inconnue')}")

            elif response in ['modifier', 'm', 'mod']:
                self.console.info("Fonctionnalit√© de modification du plan √† venir...")
                self.console.print("   Pour l'instant, relancez avec une demande modifi√©e.")
            else:
                self.console.error("Ex√©cution annul√©e")

        except KeyboardInterrupt:
            self.console.warning("Interruption d√©tect√©e")
            if self.agent and self.agent.is_running:
                self.agent.stop()
                print(prompts.AGENT_STOPPED)
        except Exception as e:
            self.logger.error(f"Erreur mode autonome: {e}", exc_info=True)
            self.console.error(f"Erreur: {e}")

    def _quit(self):
        """Quitte l'application"""
        self.running = False
        print(prompts.GOODBYE_MESSAGE)
        self.logger.info("Terminal IA arr√™t√©")
        sys.exit(0)
