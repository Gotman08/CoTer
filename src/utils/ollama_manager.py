"""
Ollama Server Manager
G√®re le d√©marrage automatique et la d√©tection du serveur Ollama
"""

import subprocess
import time
import platform
import psutil
import requests
from typing import Tuple, Optional


class OllamaManager:
    """Gestionnaire du serveur Ollama pour d√©marrage automatique"""

    def __init__(self, host: str = "http://localhost:11434", logger=None):
        """
        Initialise le gestionnaire Ollama

        Args:
            host: URL du serveur Ollama
            logger: Logger pour les messages
        """
        self.host = host.rstrip('/')
        self.logger = logger

        # Extraire le port de l'URL (d√©faut 11434)
        try:
            from urllib.parse import urlparse
            parsed = urlparse(self.host)
            self.port = parsed.port or 11434
        except Exception:
            self.port = 11434

    def is_server_running(self) -> Tuple[bool, str]:
        """
        V√©rifie si le serveur Ollama est en cours d'ex√©cution

        Utilise une d√©tection multicouche:
        1. Test API (principal): requ√™te HTTP √† /api/tags
        2. Test port (secondaire): v√©rification si port 11434 est bound
        3. Test process (tertiaire): recherche du process "ollama"

        Returns:
            Tuple (is_running, message)
        """
        # Test 1: API (le plus fiable)
        try:
            response = requests.get(f"{self.host}/api/tags", timeout=2)
            if response.status_code == 200:
                return True, "Ollama serve est d√©j√† en cours d'ex√©cution"
        except requests.exceptions.ConnectionError:
            # Serveur pas accessible, continuer avec autres tests
            pass
        except requests.exceptions.Timeout:
            # Timeout, probablement pas en cours
            pass
        except Exception as e:
            if self.logger:
                self.logger.debug(f"Erreur test API Ollama: {e}")

        # Test 2: Port (utile pour diagnostic)
        if self._check_port_in_use():
            # Port utilis√© mais API ne r√©pond pas
            return False, f"Le port {self.port} est utilis√© mais Ollama ne r√©pond pas"

        # Test 3: Process (diagnostic suppl√©mentaire)
        if self._check_process_running():
            # Process existe mais ne r√©pond pas
            return False, "Process Ollama d√©tect√© mais ne r√©pond pas √† l'API"

        # Aucun signe du serveur
        return False, "Ollama serve n'est pas en cours d'ex√©cution"

    def start_server(self, timeout: int = 10) -> Tuple[bool, str]:
        """
        D√©marre le serveur Ollama en arri√®re-plan

        Args:
            timeout: Temps d'attente max pour que le serveur r√©ponde (secondes)

        Returns:
            Tuple (success, message)
        """
        if self.logger:
            self.logger.info("Tentative de d√©marrage du serveur Ollama...")

        # V√©rifier si Ollama est install√©
        if not self.is_ollama_installed():
            return False, (
                "Ollama n'est pas install√©\n"
                "\n"
                "üí° Pour installer Ollama:\n"
                "   1. Visitez https://ollama.ai\n"
                "   2. T√©l√©chargez pour votre syst√®me\n"
                "   3. Suivez les instructions d'installation\n"
                "   4. Relancez Terminal IA"
            )

        try:
            # D√©marrer le serveur en arri√®re-plan
            if platform.system() == "Windows":
                # Windows: masquer la fen√™tre console
                process = subprocess.Popen(
                    ["ollama", "serve"],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
            else:
                # Linux/Mac/WSL: d√©tacher du processus parent
                process = subprocess.Popen(
                    ["ollama", "serve"],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    start_new_session=True
                )

            if self.logger:
                self.logger.info(f"Process Ollama d√©marr√© (PID: {process.pid})")

            # Attendre que le serveur r√©ponde
            if self._wait_for_server(timeout):
                return True, "Ollama serve d√©marr√© avec succ√®s"
            else:
                return False, (
                    f"Ollama serve a d√©marr√© mais ne r√©pond pas apr√®s {timeout}s\n"
                    "\n"
                    "üí° V√©rifications sugg√©r√©es:\n"
                    f"   1. V√©rifiez les logs: ~/.ollama/logs/\n"
                    "   2. V√©rifiez que le port {self.port} n'est pas bloqu√©\n"
                    "   3. Essayez de lancer manuellement: ollama serve"
                )

        except FileNotFoundError:
            return False, (
                "Commande 'ollama' introuvable\n"
                "\n"
                "üí° Ollama n'est peut-√™tre pas dans votre PATH:\n"
                "   1. V√©rifiez l'installation: which ollama\n"
                "   2. R√©installez si n√©cessaire: https://ollama.ai"
            )

        except PermissionError:
            return False, (
                "Permission refus√©e pour d√©marrer Ollama\n"
                "\n"
                "üí° Solutions possibles:\n"
                f"   1. V√©rifiez les permissions sur le port {self.port}\n"
                "   2. Essayez avec les privil√®ges appropri√©s\n"
                "   3. V√©rifiez les permissions du binaire ollama"
            )

        except Exception as e:
            if self.logger:
                self.logger.error(f"Erreur d√©marrage Ollama: {e}", exc_info=True)
            return False, f"Erreur inattendue lors du d√©marrage: {str(e)}"

    def ensure_server_running(self) -> Tuple[bool, str]:
        """
        Garantit que le serveur Ollama est en cours d'ex√©cution

        V√©rifie d'abord si le serveur tourne, sinon tente de le d√©marrer.
        C'est la m√©thode principale √† appeler au d√©marrage de l'application.

        Returns:
            Tuple (success, message)
        """
        # √âtape 1: V√©rifier si d√©j√† en cours
        is_running, check_message = self.is_server_running()

        if is_running:
            if self.logger:
                self.logger.info("Serveur Ollama d√©j√† actif")
            return True, check_message

        # √âtape 2: Pas en cours, afficher le statut
        if self.logger:
            self.logger.info(check_message)

        print(f"‚è≥ {check_message}...")
        print("üöÄ D√©marrage de Ollama serve...")

        # √âtape 3: Tenter de d√©marrer
        success, start_message = self.start_server()

        if success and self.logger:
            self.logger.info("Serveur Ollama d√©marr√© avec succ√®s")

        return success, start_message

    def is_ollama_installed(self) -> bool:
        """
        V√©rifie si le binaire Ollama est disponible dans le PATH

        Returns:
            True si Ollama est install√©, False sinon
        """
        try:
            # Essayer d'ex√©cuter 'ollama --version' pour v√©rifier l'installation
            result = subprocess.run(
                ["ollama", "--version"],
                capture_output=True,
                timeout=5
            )
            return result.returncode == 0
        except FileNotFoundError:
            return False
        except Exception:
            return False

    def _check_port_in_use(self) -> bool:
        """
        V√©rifie si le port Ollama est actuellement utilis√©

        Returns:
            True si le port est bound, False sinon
        """
        try:
            for conn in psutil.net_connections(kind='inet'):
                if conn.laddr.port == self.port and conn.status == 'LISTEN':
                    if self.logger:
                        self.logger.debug(f"Port {self.port} est utilis√©")
                    return True
        except (psutil.AccessDenied, AttributeError):
            # Permission refus√©e ou attribut manquant, skip
            pass
        except Exception as e:
            if self.logger:
                self.logger.debug(f"Erreur v√©rification port: {e}")

        return False

    def _check_process_running(self) -> bool:
        """
        V√©rifie si un process Ollama est en cours d'ex√©cution

        Returns:
            True si un process ollama est trouv√©, False sinon
        """
        try:
            for proc in psutil.process_iter(['name']):
                proc_name = proc.info['name']
                if proc_name and 'ollama' in proc_name.lower():
                    if self.logger:
                        self.logger.debug(f"Process Ollama trouv√©: {proc_name}")
                    return True
        except (psutil.AccessDenied, psutil.NoSuchProcess):
            # Permission refus√©e ou process termin√©, skip
            pass
        except Exception as e:
            if self.logger:
                self.logger.debug(f"Erreur v√©rification process: {e}")

        return False

    def _wait_for_server(self, timeout: int) -> bool:
        """
        Attend que le serveur Ollama devienne accessible

        Args:
            timeout: Temps d'attente maximum en secondes

        Returns:
            True si le serveur r√©pond dans le d√©lai, False sinon
        """
        start_time = time.time()
        retry_interval = 0.5  # V√©rifier toutes les 0.5s

        while time.time() - start_time < timeout:
            try:
                response = requests.get(f"{self.host}/api/tags", timeout=1)
                if response.status_code == 200:
                    elapsed = time.time() - start_time
                    if self.logger:
                        self.logger.info(f"Serveur Ollama pr√™t apr√®s {elapsed:.1f}s")
                    return True
            except (requests.exceptions.ConnectionError, requests.exceptions.Timeout):
                # Pas encore pr√™t, attendre
                pass
            except Exception as e:
                if self.logger:
                    self.logger.debug(f"Erreur attente serveur: {e}")

            time.sleep(retry_interval)

        # Timeout atteint
        if self.logger:
            self.logger.warning(f"Timeout atteint ({timeout}s), serveur ne r√©pond pas")

        return False
